#-*- encoding:utf-8 -*-
#
import os
import pickle
import time
import h5py
from model import Attention_sr_model
import numpy as np
import tensorflow as tf
from config import Hparams
import os
def load_pickle(path):
    '''
    Read pickle file
    '''
    with open(path,'rb') as f:
        data = pickle.load(f)

    return data

def paths_pickle_load(path,rootpath):
    '''
    Read addresses in pickle file
    '''
    paths = []
    with open(path,'rb') as f:
        data = pickle.load(f)
        for path in data:
            path = path.replace('\\','/')
            path = rootpath + path
            path = os.path.abspath(path)
            paths.append(path)
    return paths

def index2label(labels,index2phone):
    '''
    Converts the given index sequence into a phoneme sequence
    '''
    phones = []
    for label in labels:
        phone = []
        for lab in label:
            phone.append(index2phone[lab])
        phone = phone[1:-1]
        phones.append(phone)
    return phones

def extract_labels(paths):
    '''
    Read the actual label from the label file
    '''
    labels = []
    for path in paths:
        label_filename = path.split(path.split('.')[-1])[0]+'label'
        f = h5py.File(label_filename,'r')
        label = f['label'].value
        f.close()
        labels.append(label)
    return labels

def preds2phone(preds,index2phone,beam = False):
    '''
    Convert the recognized sequence into a great phoneme
    '''
    if beam:
        '''
        When the system uses beam searc
        '''

        preds2truth = []
        for batch in preds:

            sentence = batch[:,-1]
            converted_sentence = []
            for p in sentence:
                    
                    converted_phn = index2phone[p]
                    if converted_phn != '<EOS>' and converted_phn != '<SOS>':
                        converted_sentence.append(converted_phn)
            preds2truth.append(converted_sentence)
            converted_sentence = []

    else:
        '''
        When the system uses greedy decoding
        '''
        preds2truth = []
        for batch in preds:
            for sentence in batch:
                converted_sentence = [index2phone[ind] for ind in sentence]
                converted_sentence = [phn for phn in converted_sentence
                                        if phn != '<EOS>' and phn != '<SOS>']
                preds2truth.append(converted_sentence)
    return preds2truth
def inference(result_path,Hparams):
    '''
    Making predictions on test data
    '''
    test_start = time.time()
    #Read the storage address of all test data from the pickle file of test_path
    test_paths = paths_pickle_load(Hparams.test_path,Hparams.dataset_root)
    #print(test_paths)
    seed = 97
    tf.reset_default_graph()
    tf.set_random_seed(seed)
    np.random.seed(seed)
    #Extract the two required phoneme to index mapping dictionaries
    phone2index = load_pickle(Hparams.phn2ind_path)
    index2phone = load_pickle(Hparams.ind2phn_path)
    #Initialize the model
    model = Attention_sr_model(phn2ind = phone2index,
                               ind2phn = index2phone,
                               save_path = Hparams.save_path,
                               mode = 'INFER',
                               feature_dim = Hparams.feature_dim,
                               num_layer_encoder = Hparams.num_layer_encoder,
                               num_layer_decoder = Hparams.num_layer_decoder,
                               embedding_dim = Hparams.embedding_dim,
                               rnn_size_encoder = Hparams.rnn_size_encoder,
                               rnn_size_decoder = Hparams.rnn_size_decoder,
                               batch_size = 1,
                               beam_width = 10,
                               eos = Hparams.eos,
                               sos = Hparams.sos,
                               pad = Hparams.pad,
                               test_paths = test_paths,
                               is_training = False,
                               is_testing = True)
    model.build_graph()
    #Test all test data
    preds = model.infer(Hparams.save_path)

    preds_converted = preds2phone(preds,index2phone,beam = True)

    #Extract the actual label file, and convert the prediction into a phoneme sequence, and fill it into a txt file
    labels = extract_labels(test_paths)
    phone_labels = index2label(labels,index2phone)
    #print(np.shape(preds_converted))
    assert len(phone_labels) == len(preds_converted)
    #Position in file
    #Line i: data storage address
    #Line i + 1: the actual phoneme sequence of the data
    #Line i + 2: The prediction sequence generated by the model
    with open(result_path,'a+') as f:
        for i in range(len(preds_converted)):
            label = phone_labels[i]
            pred = delete_repeat(preds_converted[i])

            f.write(str(test_paths[i]) + '\n')

            for n in range(len(label)):
                if n != (len(label)-1):
                    f.write(str(label[n]) + ' ')
                else:
                    f.write(str(label[n]) + '\n')

            for m in range(len(pred)):
                if m != (len(pred) - 1):
                    f.write(str(pred[m]) + ' ')
                else:
                    f.write(str(pred[m]) + '\n')
    test_end = time.time()
    print('test has been done ! During:',str(test_end-test_start))

def main():
    result_path = 'trainable_test_result'
    inference(result_path,Hparams)
    

if __name__ == '__main__':
    main()

